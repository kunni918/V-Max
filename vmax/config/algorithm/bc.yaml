defaults:
  - /network/base
  - _self_

name: BC
unroll_length: 80
learning_rate: 1e-4
batch_size: 64
grad_updates_per_step: 8
loss_type: mse  # options: 'mae', 'mse'
buffer_size: 500_000

network:
  policy:
    type: mlp
    layer_sizes: [256, 256]
    activation: relu  # gelu, relu, selu
    final_activation: tanh
  value:
    layer_sizes: null
    activation: null
    final_activation: null
    num_networks: null
    shared_encoder: null
